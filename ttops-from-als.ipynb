{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center; margin-bottom: 40px; margin-top: 0;\">\n",
    "    <div style=\"flex: 0 0 auto; margin-left: 0; margin-bottom: 0; margin-top: 0;\">\n",
    "        <img src=\"./pics/UCSD Logo.png\" alt=\"UCSD Logo\" style=\"width: 179px; margin-bottom: 0px; margin-top: 20px;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 0 0 auto; margin-left: auto; margin-bottom: 0; margin-top: 20px;\">\n",
    "        <img src=\"./pics/LANL-logo.png\" alt=\"LANL Logo\" style=\"width: 200px; margin-bottom: 0px;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 0 0 auto; margin-left: auto; margin-bottom: 0; margin-top: 20px;\">\n",
    "        <img src=\"./pics/prowess.png\" alt=\"Prowess Logo\" style=\"width: 200px; margin-bottom: 0px;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 0 0 auto; margin-left: auto; margin-bottom: 0; margin-top: 20px;\">\n",
    "        <img src=\"./pics/wildfire.png\" alt=\"WildFire Logo\" width=\"100\"/>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<h1 style=\"text-align: center; font-size: 48px; margin-top: 0;\">Fire-Ready Forests Data Challenge</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sprint 2: Generating a Treelist from ALS\n",
    "\n",
    "In the previous sprint, you worked with a notebook exploring the FIA Database. In that notebook, we introduced a technique called **Individual Tree Detection**. If you need a refresher, you can revisit Sprint 1 - Module A and open the `fia_database.ipynb` notebook, specifically the *Preliminary Analysis* section.\n",
    "\n",
    "We also provided a file, `ttops.csv`, which contains a list of trees derived from ALS data. In this module, we will demonstrate how this list is generated.\n",
    "\n",
    "Instead of processing the entire dataset—which would require significant computation time—we will focus on a single `.laz` file. Running the full computation on this file should take approximately 20–25 minutes.\n",
    "\n",
    "## Part 1 - Canopy Height Model\n",
    "\n",
    "The first dataset we’ll extract from our ALS file is the **Canopy Height Model (CHM)**. The CHM represents the height of vegetation, such as trees, above the ground. To create it, we subtract the Digital Terrain Model (DTM)—which captures the bare ground elevation—from the Digital Surface Model (DSM). This allows us to measure the true height of vegetation in the landscape. Mathematically, it is expressed as: \n",
    "\n",
    "$$\n",
    "CHM = DSM - DTM\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we import all the libraries\n",
    "import pc_rasterize as pcr\n",
    "import glob\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dask.distributed import Client, LocalCluster, Lock\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import peak_local_max\n",
    "from pyproj import Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run our script successfully, we first need to download the file locally. Unfortunately, we can't load the file directly into memory from a URL, so we'll start by selecting one of the links from the *ALS Raw Files Download Links* file and saving it to our storage. Once you've completed this module, you can delete the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://wifire-data.sdsc.edu/nc/s/nnSMqWfZAN6Cz6m/download?path=%2Fnew_data%2FRaw%20ALS%20and%20Detected%20Trees%2FALS%20data&files=USGS_LPC_CA_SierraNevada_B22_10SGJ2967.laz&downloadStartSecret=aik5h9wexsu\"\n",
    "local_als = \"./USGS_LPC_CA_SierraNevada_B22_10SGJ2967.laz\"\n",
    "\n",
    "response = requests.get(url, stream=True)\n",
    "with open(local_als, \"wb\") as file:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        file.write(chunk)\n",
    "\n",
    "print(f\"Downloaded: {local_als}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've downloaded the file, let's take a quick look at its key details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr.get_file_quickinfo('./USGS_LPC_CA_SierraNevada_B22_10SGJ2967.laz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's proceed to build a pipeline for our file processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = glob.glob(\"./USGS_LPC_CA_SierraNevada_B22_10SGJ2967.laz\") # We load our file\n",
    "\n",
    "# Create a GeoBox grid specification with a 100m buffer around data\n",
    "geobox = pcr.build_geobox(als, resolution=1., crs=\"5070\")\n",
    "\n",
    "# Build a lazy CHM raster\n",
    "chm = pcr.rasterize(\n",
    "    als,\n",
    "    geobox,\n",
    "    cell_func=\"max\",\n",
    "    # Set custom dask chunk-size\n",
    "    chunksize=(1000, 1000),\n",
    "    nodata=np.nan,\n",
    "    pdal_filters=[\n",
    "    {\n",
    "        \"type\":\"filters.range\",\n",
    "        \"limits\":\"Classification[1:5]\" # Keep points classified as 'vegetation' - https://desktop.arcgis.com/en/arcmap/latest/manage-data/las-dataset/lidar-point-classification.htm\n",
    "    },\n",
    "    {\n",
    "      \"type\":\"filters.outlier\" # Remove outliers\n",
    "    },\n",
    "    {\n",
    "        \"type\":\"filters.hag_nn\" # Compute Height Above Ground (HAG) using the nearest-neighbor method. \n",
    "    },\n",
    "    {\n",
    "        \"type\":\"filters.ferry\",\n",
    "        \"dimensions\":\"HeightAboveGround=>Z\" # Move the computed HAG values into the `Z` coordinate for easier processing.  \n",
    "    },\n",
    "    {\n",
    "      \"type\":\"filters.outlier\" # Remove outliers again\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"filters.expression\",\n",
    "        \"expression\": \"Z < 75\" # Filters out points higher than 75m (unrealistic height in our context) \n",
    "    }\n",
    "    ]\n",
    ")\n",
    "# A quick look to our xarray\n",
    "chm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our pipeline ready, we will proceed with the computation. The next line will take 10-20 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with LocalCluster(n_workers=8, threads_per_worker=1, memory_limit='24GB') as cluster, Client(cluster) as client:\n",
    "    chm_squeezed = chm.squeeze()  # We remove an extra dimension with no data\n",
    "    chm_squeezed.rio.to_raster(\"./chm.tiff\", tiled=True, lock=Lock(\"rio\"))\n",
    "print(\"Successfuly computed the CHM!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The source repository of the method that we applied in this notebook can be found [here](https://github.com/UM-RMRS/pc-rasterize)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - TreeTops\n",
    "\n",
    "Ok, now that we have our CHM ready, we can proceed to generate our list of trees. But first, let's visualize our CHM raster file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chm_path = \"./chm.tiff\"\n",
    "with rasterio.open(chm_path) as src:\n",
    "    chm = src.read(1)  \n",
    "    transform = src.transform  # Affine transform for georeferencing\n",
    "    crs = src.crs  # Get raster Coordinate Reference System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's quickly visualize our raster\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(chm, cmap=\"viridis\", interpolation=\"nearest\")\n",
    "plt.colorbar(label=\"Canopy Height (m)\")\n",
    "plt.title(\"Canopy Height Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty cool right? \n",
    "\n",
    "With our CHM ready, it's time to move on to **tree detection**—extracting their heights and precise coordinates. Let’s get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize CHM \n",
    "chm_norm = (chm - np.nanmin(chm)) / (np.nanmax(chm) - np.nanmin(chm))\n",
    "\n",
    "# Locate tree tops using local maxima filtering\n",
    "tree_tops = peak_local_max(chm_norm, min_distance=3, threshold_abs=0.1, exclude_border=False)\n",
    "\n",
    "# Convert pixel coordinates to geospatial coordinates and extract heights\n",
    "tree_points = []\n",
    "for row, col in tree_tops:\n",
    "    x, y = transform * (int(col), int(row))  \n",
    "    height = chm[row, col] \n",
    "    tree_points.append((height, y, x)) \n",
    "\n",
    "df = pd.DataFrame(tree_points, columns=[\"HT\", \"y\", \"x\"])\n",
    "\n",
    "# Let´s look at the df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the distribution of tree heights\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(df[\"HT\"], bins=30, edgecolor=\"black\", alpha=0.7)\n",
    "plt.xlabel(\"Tree Height (HT)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Tree Heights (HT)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Lat/Lon system\n",
    "if crs and crs.to_epsg() != 4326:\n",
    "    transformer = Transformer.from_crs(crs.to_epsg(), \"EPSG:4326\", always_xy=True)\n",
    "    df[\"x\"], df[\"y\"] = transformer.transform(df[\"x\"].values, df[\"y\"].values) \n",
    "\n",
    "# Save CSV\n",
    "df.to_csv(\"./ttops.csv\", index=False)\n",
    "print(f\"TreeTops saved to ./data/ttops.csv with {len(df)} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! Now you know how to generate a ttops file like the one you used in the previous sprint, and that you will continue to use in the following sprints. \n",
    "\n",
    "If you're interested in learning more about Individual Tree Detection (ITD) and the various libraries and software tools available for creating similar tree lists, check out the following resources:\n",
    "\n",
    "- https://research.fs.usda.gov/treesearch/59063\n",
    "- https://tgoodbody.github.io/lidRtutorial/06_its.html\n",
    "- https://www.mathworks.com/help/lidar/ug/extraction-of-forest-metrics-and-individual-tree-attributes.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
